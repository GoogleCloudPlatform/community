---
title: Scaling time series absence alerts with Stackdriver
description: Create alerts for missing monitoring data with Stackdriver, avoiding duplicate alerts so that you aren't overwhelmed with notifications.
author: alexamies
tags: Stackdriver, monitoring
date_published: 2019-11-27
---

This tutorial describes creating alerts for missing monitoring data with Stackdriver alerts, avoiding duplicate alerts so
that you are not overwhelmed with notifications. For example, suppose that you have 100 time series and you want to find out 
when any one of them is missing. If one or two time series are missing, you want exactly one alert. When there is a total
outage, you still want to get one alert, not 100 alerts. 

The diagram below shows the general flow: The test app divides task processing into multiple partitions, each of 
which generates a time series, which are sent to Stackdriver. When there is a missing time series, Stackdriver sends an 
alert to a user.

![schematic diagram](https://storage.googleapis.com/gcp-community/tutorials/absence-alerts-stackdriver/schematic.png)

The instructions are provided for a Linux development environment, such as [Cloud Shell](https://cloud.google.com/shell/).
However, you can also run the application on Google Compute Engine, Kubernetes, a serverless environment, or outside of
Google Cloud.

The tutorial assumes that you're familiar with Google Cloud, including Stackdriver Monitoring and Alerting. This tutorial
builds on the discussion in [Alerting policies in depth](https://cloud.google.com/monitoring/alerts/concepts-indepth).

## Objectives

* Learn how to create alerts using `gcloud` commands.
* Learn to how to minimize the number of alerts generated by reducing multiple time series, detecting when one is missing.

## Costs

This tutorial uses billable components of Google Cloud, including Stackdriver Monitoring.

Use the [Pricing Calculator](https://cloud.google.com/products/calculator) to generate a cost estimate based on your 
projected usage. This tutorial only generates a small amount of Stackdriver Monitoring data, which may fall within the free
allotment.

## Before you begin

For this tutorial, you need a GCP
[project](https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy#projects).
You can create a new one, or you can select a project that you have already created if it is not an existing Stackdriver
workspace:

1.  Select or create a GCP project.

    [GO TO THE MANAGE RESOURCES PAGE](https://console.cloud.google.com/cloud-resource-manager)

1.  Enable billing for your project.

    [ENABLE BILLING](https://support.google.com/cloud/answer/6293499#enable-billing)

1.  In the Google Cloud Console, go to [Monitoring](https://console.cloud.google.com/monitoring).

1.  Click **New workspace**, and then click **Add**.

    It takes a few minutes to create the workspace.

1.  Click **Alerting | Policies overview**.

    The list should be empty at this point unless you have created policies previously.

1.  Open [Cloud Shell](https://cloud.google.com/shell/#) in the Cloud Console.

1.  Clone the code for the project and change to the directory for this example:

        git clone https://github.com/GoogleCloudPlatform/professional-services.git
        cd professional-services/examples/alert-absence-dedup

1.  Enable the Stackdriver Monitoring API:

        gcloud services enable monitoring.googleapis.com

Note that if the project is a monitored project in a Stackdriver workspace corresponding to another project, then any 
alerting policy definitions will need to be written against the associated workspace project rather than the project in 
which these virtual machines are being created. The instructions in this tutorial assume that the Stackdriver workspace 
corresponds to the selected project.

When you finish this tutorial, you can avoid continued billing by deleting the resources you created. See
[Cleaning up](#cleaning-up) for more detail.

## Description of the policy

The alert will be created with the
[`gcloud alpha monitoring policies create`](https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create)
command, which uses the Stackdriver Monitoring API. The specific REST resource used in that API is
[AlertPolicy](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies#AlertPolicy).

This alert policy has two conditions:

-   Condition #1: Detect when the logic for writing time-series is broken.

    Use a metric absence with a “crossSeriesReducer” that combines all of the time series from different data sources 
    together. That is, only fire when *all* of the time series are absent, which would be expected to happen if there is 
    something fundamentally broken with the time series writing logic, with the underlying assumption that all of the data 
    sources share the same logic for reporting the data.

-   Condition #2: Detect when one or more partitions fail to report data independent of the others⁠—i.e., a cause other than
    the time series writing logic, such as loss of connectivity of a particular instance.

    For this condition, we use a
    [metric threshold](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies#MetricThreshold)
    rather than a
    [metric absence](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies#MetricAbsence)
    with a REDUCE_COUNT crossSeriesReducer
    [aggregation](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies#Aggregation)
    that reports a total count of the number of time-series that were found. We apply a threshold to the total count, since
    we know how many shards there ought to be. Alternatively, we could apply a threshold to an ALIGN_DELTA (or 
    ALIGN_PERCENT_CHANGE) of the REDUCE_COUNT output to detect if the change in the total number of data sources goes down 
    by a certain amount. The former (directly thresholding on the REDUCE_COUNT output) makes sense if you know that a 
    precise number of data sources is expected. The latter (computing an absolute or relative change in number and 
    thresholding on the change) is useful if there isn't a fixed number of data sources, but the overall number of data 
    sources is expected to monotonically increase or is expected to only change slowly, with a non-zero decrease or a very 
    high percent change in number reflecting an issue with the service.

## Detailed steps

This section includes detailed steps for some specific metrics and testing.

The example app is based on the Go code in 
[Custom metrics with OpenCensus](https://cloud.google.com/monitoring/custom-metrics/open-census). It generates time series 
for a metric called `task_latency_distribution`. The app code has been extended to tag the time series with partition labels 
and run indefinitely.

If you run the test app on a Compute Engine instance, Google Kubernetes Engine, or Google Cloud serverless 
environment, then you do not need to create a service account or download the credentials. For details, see
[Setting up authentication](https://cloud.google.com/monitoring/docs/reference/libraries#setting_up_authentication).

### Install Go

[Download](https://golang.org/dl/) and install the latest version of Go.

### Build the test app

Run this command to build the test app:

        go build

### Set up authentication

Set up authentication for the Stackdriver client library.

1.  Set the project ID in a shell variable:

        export GOOGLE_CLOUD_PROJECT=[your_project_ID]

1.  Create a service account:

        SA_NAME=stackdriver-metrics-writer
        gcloud iam service-accounts create $SA_NAME \
          --display-name="Stackdriver Metrics Writer" 

1.  Bind the service account to a policy:

        SA_ID="$SA_NAME@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com"
        gcloud projects add-iam-policy-binding $GOOGLE_CLOUD_PROJECT \
          --member "serviceAccount:$SA_ID" --role "roles/monitoring.metricWriter"

1.  Generate a credentials file with an exported variable `GOOGLE_APPLICATION_CREDENTIALS` referring to it:

        mkdir -p ~/.auth
        chmod go-rwx ~/.auth
        export GOOGLE_APPLICATION_CREDENTIALS=~/.auth/stackdriver_demo_credentials.json 
        gcloud iam service-accounts keys create $GOOGLE_APPLICATION_CREDENTIALS \
         --iam-account $SA_ID

### Run the test app

Run the program with three partitions, labeled `1`, `2`, and `3`:

    ./alert-absence-demo --labels "1,2,3"

This writes three time series, with the given labels. A few minutes after starting the app, you should be able to see
the time series data in the Stackdriver Metric explorer, as in the screenshot below.

![schematic diagram](https://storage.googleapis.com/gcp-community/tutorials/absence-alerts-stackdriver/metrics_explorer.png)

Notice that the time series can be grouped by partition.

### Create a notification channel

The notification channel can be created with the
[`gcloud alpha monitoring channels`](https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/channels/)
command. 

Create a notification channel with the command, replacing `[your_email_address]` with your email address:

    EMAIL="[your_email_address]"
    CHANNEL=$(gcloud alpha monitoring channels create \
      --channel-labels=email_address=$EMAIL \
      --display-name="Email to project owner" \
      --type=email \
      --format='value(name)')

The shell variable `CHANNEL` now contains  the name of the notification channel created, which can be used in creating an 
alerting policy.

### Create the alerting policy

The alerting policy can be created with the
[`gcloud alpha monitoring policies create`](https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create)
command. The details of the policy are defined in the
[`alert_policy.json`](https://github.com/GoogleCloudPlatform/professional-services/blob/master/examples/alert-absence-dedup/alert_policy.json) file.

Run the following in a new command shell:

    gcloud alpha monitoring policies create \
      --notification-channels=$CHANNEL \
      --documentation-from-file=policy_doc.md \
      --policy-from-file=alert_policy.json

The policy includes the notification channel created above and the
[alert documentation](https://cloud.google.com/monitoring/alerts/using-alerting-ui#documentation)
content in markdown form in the `policy_doc.md` file. This is a  good place to add playbook-like instructions to assist the 
on-call person who responds to the alert. The documentation includes
[template variables](https://cloud.google.com/monitoring/alerts/doc-variables)
to make the content as relevant as possible.

At this point, no alerts should be firing. You can check that in the Stackdriver Monitoring console alert policy detail.

### Test the policy

1.  Kill the processes with Control-c and restart the app with only two partitions:

        ./alert-absence-demo --labels "1,2"

    An alert should be generated in about 5 minutes with a subject like "One of the time series is absent", as in this
    screenshot:

    ![Absence alert with one time series missing](https://storage.googleapis.com/gcp-community/tutorials/absence-alerts-stackdriver/alert_one_missing.png)

1.  Restart the process with three partitions:

        ./alert-absence-demo "1,2,3"

    After a few minutes, the alert should be resolved.

1.  Stop the process and restart it with only one partition:

        ./alert-absence-demo --labels "1"

1.  Check that only one alert is fired, as in this example:

    ![Absence alert with two time series missing](https://storage.googleapis.com/gcp-community/tutorials/absence-alerts-stackdriver/alert_two_missing.png)

1.  Start the instances and wait for the incident to be resolved.

1.  Stop the process and do not restart it.

    You should see an alert that indicates all time series are absent, as in this screenshot:

    ![Absence alert with all time series missing](https://storage.googleapis.com/gcp-community/tutorials/absence-alerts-stackdriver/alert_all_missing.png)

## Cleaning up

The easiest way to avoid incurring charges to your Google Cloud account for the resources used in this tutorial is to delete
the project that you created for the tutorial.

### Delete the project

1.  In the Cloud Console, go to the Projects page.

    [GO TO THE PROJECTS PAGE](https://console.cloud.google.com/iam-admin/projects)

1.  In the project list, select the project that you want to delete and click **Delete**.

1.  In the dialog, type the project ID, and then click **Shut down** to delete the project.

## What's next

* Take a look at some more [sample alert policies](https://cloud.google.com/monitoring/alerts/policies-in-json).
* Try out other Google Cloud features for yourself. Have a look at our
[tutorials](https://cloud.google.com/tutorials/).
