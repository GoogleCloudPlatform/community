{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the [original code](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/estimators/abalone.py) from [this excellent tutorial](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/estimators/abalone.py) and inlines it into a Datalab notebook.\n",
    "\n",
    "The model used is a 2 hidden layer, feed forward neural net.  Here's the definition.\n",
    "\n",
    "```\n",
    "first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "# Connect the second hidden layer to first hidden layer with relu\n",
    "second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "# Connect the output layer to second hidden layer (no activation fn)\n",
    "output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "```\n",
    "\n",
    "You should familiarize yourself with both the tutorial and code below and run this notebook in its entirety before proceeding to the [next notebook](3-tweaked-original-neural-net.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run this notebook you will see output from model training and evaluation such as the following.\n",
    "\n",
    "```\n",
    "INFO:tensorflow:loss = 4.63147, step = 4901 (0.192 sec)\n",
    "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp_Figkd/model.ckpt.\n",
    "INFO:tensorflow:Loss for final step: 4.62195.\n",
    "INFO:tensorflow:Starting evaluation at 2017-08-03-15:45:47\n",
    "INFO:tensorflow:Restoring parameters from /tmp/tmp_Figkd/model.ckpt-5000\n",
    "INFO:tensorflow:Evaluation [1/1]\n",
    "INFO:tensorflow:Finished evaluation at 2017-08-03-15:45:48\n",
    "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.38538, rmse = 2.32064\n",
    "Loss: 5.38538\n",
    "Root Mean Squared Error: 2.32064\n",
    "```\n",
    "\n",
    "Which shows the final few steps of the training of the model together with the final result of training.  The final result of training of interest to you is the [Root Mean Square Error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation).  Essentially it is a measure of how bad our model is - how badly the model makes predictions on tesing data - and the smaller the number (the less bad :-)) the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is downloaded to /tmp/tmpz3LEcj\n",
      "Test data is downloaded to /tmp/tmpgu44w9\n",
      "Prediction data is downloaded to /tmp/tmphsV6y1\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2gjy8Z\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7ed0015f10>, '_model_dir': '/tmp/tmp2gjy8Z', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp2gjy8Z/model.ckpt.\n",
      "INFO:tensorflow:loss = 108.742, step = 1\n",
      "INFO:tensorflow:global_step/sec: 417.898\n",
      "INFO:tensorflow:loss = 8.03166, step = 101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.374\n",
      "INFO:tensorflow:loss = 7.72569, step = 201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.459\n",
      "INFO:tensorflow:loss = 7.55893, step = 301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.921\n",
      "INFO:tensorflow:loss = 7.45796, step = 401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.958\n",
      "INFO:tensorflow:loss = 7.38968, step = 501 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.429\n",
      "INFO:tensorflow:loss = 7.33732, step = 601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.687\n",
      "INFO:tensorflow:loss = 7.29126, step = 701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.091\n",
      "INFO:tensorflow:loss = 7.24189, step = 801 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.675\n",
      "INFO:tensorflow:loss = 7.16664, step = 901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.587\n",
      "INFO:tensorflow:loss = 7.11552, step = 1001 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.714\n",
      "INFO:tensorflow:loss = 7.07394, step = 1101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.416\n",
      "INFO:tensorflow:loss = 7.03367, step = 1201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.044\n",
      "INFO:tensorflow:loss = 6.99441, step = 1301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.812\n",
      "INFO:tensorflow:loss = 6.95485, step = 1401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.473\n",
      "INFO:tensorflow:loss = 6.91453, step = 1501 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.831\n",
      "INFO:tensorflow:loss = 6.87332, step = 1601 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.064\n",
      "INFO:tensorflow:loss = 6.83119, step = 1701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.538\n",
      "INFO:tensorflow:loss = 6.78781, step = 1801 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.999\n",
      "INFO:tensorflow:loss = 6.74308, step = 1901 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.066\n",
      "INFO:tensorflow:loss = 6.6968, step = 2001 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.445\n",
      "INFO:tensorflow:loss = 6.64887, step = 2101 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.248\n",
      "INFO:tensorflow:loss = 6.59908, step = 2201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.352\n",
      "INFO:tensorflow:loss = 6.5473, step = 2301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.647\n",
      "INFO:tensorflow:loss = 6.49353, step = 2401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.244\n",
      "INFO:tensorflow:loss = 6.43757, step = 2501 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.386\n",
      "INFO:tensorflow:loss = 6.37929, step = 2601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.903\n",
      "INFO:tensorflow:loss = 6.31861, step = 2701 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.456\n",
      "INFO:tensorflow:loss = 6.25541, step = 2801 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.862\n",
      "INFO:tensorflow:loss = 6.18964, step = 2901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.338\n",
      "INFO:tensorflow:loss = 6.12135, step = 3001 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.74\n",
      "INFO:tensorflow:loss = 6.05062, step = 3101 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.863\n",
      "INFO:tensorflow:loss = 5.97756, step = 3201 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.972\n",
      "INFO:tensorflow:loss = 5.90241, step = 3301 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.889\n",
      "INFO:tensorflow:loss = 5.82554, step = 3401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.474\n",
      "INFO:tensorflow:loss = 5.74742, step = 3501 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.41\n",
      "INFO:tensorflow:loss = 5.66854, step = 3601 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.432\n",
      "INFO:tensorflow:loss = 5.58962, step = 3701 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.895\n",
      "INFO:tensorflow:loss = 5.51144, step = 3801 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.994\n",
      "INFO:tensorflow:loss = 5.43482, step = 3901 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.402\n",
      "INFO:tensorflow:loss = 5.36061, step = 4001 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.739\n",
      "INFO:tensorflow:loss = 5.28967, step = 4101 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.573\n",
      "INFO:tensorflow:loss = 5.2228, step = 4201 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.7\n",
      "INFO:tensorflow:loss = 5.16066, step = 4301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.218\n",
      "INFO:tensorflow:loss = 5.10382, step = 4401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.875\n",
      "INFO:tensorflow:loss = 5.05262, step = 4501 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.763\n",
      "INFO:tensorflow:loss = 5.00714, step = 4601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.408\n",
      "INFO:tensorflow:loss = 4.96734, step = 4701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.28\n",
      "INFO:tensorflow:loss = 4.93298, step = 4801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.893\n",
      "INFO:tensorflow:loss = 4.90371, step = 4901 (0.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp2gjy8Z/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.87927.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-21-19:29:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2gjy8Z/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-21-19:29:56\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.57141, rmse = 2.36038\n",
      "Loss: 5.57141\n",
      "Root Mean Squared Error: 2.36038\n",
      "WARNING:tensorflow:From <ipython-input-1-b1ded8480f2c>:157: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2gjy8Z/model.ckpt-5000\n",
      "Prediction 1: 5.20847713093\n",
      "Prediction 2: 10.2588934235\n",
      "Prediction 3: 7.21142357843\n",
      "Prediction 4: 10.6182608272\n",
      "Prediction 5: 11.0833406892\n",
      "Prediction 6: 9.2851135716\n",
      "Prediction 7: 11.191439847\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data, predict_data):\n",
    "  \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "  if train_data:\n",
    "    train_file_name = train_data\n",
    "  else:\n",
    "    train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "        train_file.name)\n",
    "    train_file_name = train_file.name\n",
    "    train_file.close()\n",
    "    print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "  if test_data:\n",
    "    test_file_name = test_data\n",
    "  else:\n",
    "    test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "    test_file_name = test_file.name\n",
    "    test_file.close()\n",
    "    print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "  if predict_data:\n",
    "    predict_file_name = predict_data\n",
    "  else:\n",
    "    predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "        predict_file.name)\n",
    "    predict_file_name = predict_file.name\n",
    "    predict_file.close()\n",
    "    print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "  return train_file_name, test_file_name, predict_file_name\n",
    "\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \"\"\"Model function for Estimator.\"\"\"\n",
    "\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features) with relu activation\n",
    "  first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "  # Connect the second hidden layer to first hidden layer with relu\n",
    "  second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float64), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load datasets\n",
    "  abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "      FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "  # Training examples\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Test examples\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set of 7 examples for which to predict abalone ages\n",
    "  prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set model params\n",
    "  model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "  # Instantiate Estimator\n",
    "  nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "  \n",
    "  def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  # Fit\n",
    "  nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "  # Score accuracy\n",
    "  def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "  print(\"Loss: %s\" % ev[\"loss\"])\n",
    "  print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "\n",
    "  # Print out predictions\n",
    "  predictions = nn.predict(x=prediction_set.data, as_iterable=True)\n",
    "  for i, p in enumerate(predictions):\n",
    "    print(\"Prediction %s: %s\" % (i + 1, p[\"ages\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "  parser.add_argument(\n",
    "      \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "  parser.add_argument(\n",
    "      \"--predict_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the prediction data.\")\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
