{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a version of our model that integrates Keras into the customer estimator from tf.contrib.learn we can proceed to add in additional code required to train this model on Google Cloud Machine Learning Engine (CMLE).  There are a relatively small number of changes required to get a big uplift in functionality together with the ability to run locally or deploy to CMLE with equal ease from the command line.  Changes will be explained as the solution progresses.\n",
    "\n",
    "At a high level we do three things:\n",
    "\n",
    "* Change the mechanism for accessing training/test data from reading directly from local files to reading files from Google Cloud Storage (GCS).\n",
    "* Encapsulate the model and additional requirements into an Experiment which is in turn managed by a learn_runner from tf.contrib.learn.  Experiment has the functionality required to train and evaluate a model in a distributed environment, including checkpointing progress, reporting summaries that can be consumed by TensorBoard, etc.  In turn learn_runner is a utility that helps run and tune an Experiment.\n",
    "* Add in a main method with argument parsing to allow this to be saved and executed as a script when running on CMLE\n",
    "\n",
    "Both of these are called out below in the code.\n",
    "\n",
    "One change from usual practice called out in advance is that usually TensorFlow modelling, especially for CMLE, the model is placed in one file and the associated code to run it is placed in another.  These are usually called model and task.  This is a sensible separation of concerns because it makes it easier to swap models easily.  However, for the purposes of this tutorial I'm combining both into a single notebook/file for convenience.\n",
    "\n",
    "When you're happy with this proceed to the [next notebook](6-distributed-keras.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell deletes a local directory used when this model is trained locally (i.e. by running this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf abalone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import (saved_model_export_utils)\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads the data from file in GCS, decodes it into tensors, and also adds in functionality to allow the data to be accessed in epochs (as well as training steps) as well as being shuffled when required.  E.g. When training you'll often not care about the exact number of training steps, you'll care about the number of times you cycle through the entire dataset (an epoch) and when you do cycle through the entire dataset it is a best practice to shuffle the data before using it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    'length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
    "    'viscera_weight', 'shell_weight', 'num_rings'\n",
    "]\n",
    "CSV_COLUMN_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "PREDICTED_COLUMN = 'num_rings'\n",
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('length'),\n",
    "    tf.feature_column.numeric_column('diameter'),\n",
    "    tf.feature_column.numeric_column('height'),\n",
    "    tf.feature_column.numeric_column('whole_weight'),\n",
    "    tf.feature_column.numeric_column('shucked_weight'),\n",
    "    tf.feature_column.numeric_column('viscera_weight'),\n",
    "    tf.feature_column.numeric_column('shell_weight'),\n",
    "]\n",
    "\n",
    "UNUSED_COLUMNS = set(CSV_COLUMNS) - {col.name for col in INPUT_COLUMNS} - {PREDICTED_COLUMN}\n",
    "\n",
    "def parse_csv(rows_string_tensor):\n",
    "    columns = tf.decode_csv(rows_string_tensor, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "\n",
    "    for col in UNUSED_COLUMNS:\n",
    "        features.pop(col)\n",
    "\n",
    "    for key, value in six.iteritems(features):\n",
    "        features[key] = tf.expand_dims(features[key], -1)\n",
    "    return features\n",
    "\n",
    "def generate_input_fn(filenames,\n",
    "                      num_epochs=None,\n",
    "                      shuffle=True,\n",
    "                      skip_header_lines=0,\n",
    "                      batch_size=64):\n",
    "  \n",
    "    def _input_fn():\n",
    "  \n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=shuffle)\n",
    "        reader = tf.TextLineReader(skip_header_lines=skip_header_lines)\n",
    "\n",
    "        _, rows = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "        features = parse_csv(rows)\n",
    "\n",
    "        if shuffle:\n",
    "            features = tf.train.shuffle_batch(\n",
    "                features,\n",
    "                batch_size,\n",
    "                min_after_dequeue=2 * batch_size + 1,\n",
    "                capacity=batch_size * 10,\n",
    "                num_threads=multiprocessing.cpu_count(),\n",
    "                enqueue_many=True,\n",
    "                allow_smaller_final_batch=True\n",
    "            )\n",
    "        else:\n",
    "            features = tf.train.batch(\n",
    "                features,\n",
    "                batch_size,\n",
    "                capacity=batch_size * 10,\n",
    "                num_threads=multiprocessing.cpu_count(),\n",
    "                enqueue_many=True,\n",
    "                allow_smaller_final_batch=True\n",
    "            )\n",
    "\n",
    "        return features, features.pop(PREDICTED_COLUMN)\n",
    "  \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_model_fn(learning_rate):\n",
    "    \n",
    "    def _model_fn(mode, features, labels):\n",
    "\n",
    "        (length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight) = INPUT_COLUMNS\n",
    "\n",
    "        transformed_columns = [\n",
    "            length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight\n",
    "        ]\n",
    "\n",
    "        inputs = tf.feature_column.input_layer(features, transformed_columns)\n",
    "\n",
    "        first_hidden_layer = Dense(10, activation='relu')(inputs)\n",
    "        second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "        output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "        if mode in (Modes.PREDICT, Modes.EVAL):\n",
    "            predictions = tf.reshape(output_layer, [-1])\n",
    "            predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "        if mode in (Modes.TRAIN, Modes.EVAL):\n",
    "            loss = tf.losses.mean_squared_error(labels, output_layer)\n",
    "\n",
    "        if mode == Modes.TRAIN:\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                global_step=tf.contrib.framework.get_global_step(),\n",
    "                learning_rate=learning_rate,\n",
    "                optimizer=\"SGD\")\n",
    "        \n",
    "        if mode == Modes.TRAIN:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        if mode == Modes.EVAL:\n",
    "            eval_metric_ops = {\n",
    "                \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "                    tf.cast(labels, tf.float32), predictions)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "        if mode == Modes.PREDICT:\n",
    "            export_outputs = {\n",
    "                'prediction': tf.estimator.export.RegressionOutput(predictions)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, predictions=predictions_dict, export_outputs=export_outputs)\n",
    "    \n",
    "    return _model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_experiment_fn(**experiment_args):  \n",
    "  \n",
    "    def _experiment_fn(run_config, hparams):\n",
    "\n",
    "        train_input = generate_input_fn(\n",
    "            hparams.train_files,\n",
    "            num_epochs=hparams.num_epochs,\n",
    "            batch_size=hparams.train_batch_size,\n",
    "        )\n",
    "\n",
    "        test_input = generate_input_fn(\n",
    "            hparams.eval_files,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        return tf.contrib.learn.Experiment(\n",
    "            tf.estimator.Estimator(\n",
    "                generate_model_fn(learning_rate=hparams.learning_rate),\n",
    "                config=run_config\n",
    "            ),\n",
    "            train_input_fn=train_input,\n",
    "            eval_input_fn=test_input,\n",
    "            **experiment_args\n",
    "        )\n",
    "\n",
    "    return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def example_serving_input_fn():\n",
    "    example_bytestring = tf.placeholder(\n",
    "        shape=[None],\n",
    "        dtype=tf.string,\n",
    "    )\n",
    "    features = tf.parse_example(\n",
    "        example_bytestring,\n",
    "        tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "    )\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features, {'example_proto': example_bytestring})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'abalone_output', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f71f35f0b50>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-21-19:35:19\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-21-19:35:21\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 97.8174, rmse = 9.89027\n",
      "INFO:tensorflow:Validation (step 1): loss = 97.8174, global_step = 1, rmse = 9.89027\n",
      "INFO:tensorflow:loss = 55.1853, step = 1\n",
      "INFO:tensorflow:global_step/sec: 35.4629\n",
      "INFO:tensorflow:loss = 15.7632, step = 101 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.515\n",
      "INFO:tensorflow:loss = 1.11121, step = 201 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.583\n",
      "INFO:tensorflow:loss = 4.09976, step = 301 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.62\n",
      "INFO:tensorflow:loss = 54.8028, step = 401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.698\n",
      "INFO:tensorflow:loss = 2.47763, step = 501 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.327\n",
      "INFO:tensorflow:loss = 0.0346893, step = 601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.385\n",
      "INFO:tensorflow:loss = 2.19193, step = 701 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.994\n",
      "INFO:tensorflow:loss = 0.00961196, step = 801 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 571.37\n",
      "INFO:tensorflow:loss = 0.442532, step = 901 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.322\n",
      "INFO:tensorflow:loss = 9.99328, step = 1001 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.437\n",
      "INFO:tensorflow:loss = 0.30835, step = 1101 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 596.52\n",
      "INFO:tensorflow:loss = 0.291386, step = 1201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 575.556\n",
      "INFO:tensorflow:loss = 0.14255, step = 1301 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.673\n",
      "INFO:tensorflow:loss = 2.51685, step = 1401 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.181\n",
      "INFO:tensorflow:loss = 50.2531, step = 1501 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.726\n",
      "INFO:tensorflow:loss = 0.00189573, step = 1601 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.605\n",
      "INFO:tensorflow:loss = 0.00137378, step = 1701 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.562\n",
      "INFO:tensorflow:loss = 28.1556, step = 1801 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.623\n",
      "INFO:tensorflow:loss = 1.04446, step = 1901 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.516\n",
      "INFO:tensorflow:loss = 0.71727, step = 2001 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.483\n",
      "INFO:tensorflow:loss = 0.0888616, step = 2101 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.399\n",
      "INFO:tensorflow:loss = 0.208195, step = 2201 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.49\n",
      "INFO:tensorflow:loss = 6.43551, step = 2301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.06\n",
      "INFO:tensorflow:loss = 23.6452, step = 2401 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.564\n",
      "INFO:tensorflow:loss = 54.5276, step = 2501 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.905\n",
      "INFO:tensorflow:loss = 4.18974, step = 2601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.689\n",
      "INFO:tensorflow:loss = 1.38917, step = 2701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.671\n",
      "INFO:tensorflow:loss = 2.53918, step = 2801 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.139\n",
      "INFO:tensorflow:loss = 0.973434, step = 2901 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.595\n",
      "INFO:tensorflow:loss = 0.334397, step = 3001 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.637\n",
      "INFO:tensorflow:loss = 2.09455, step = 3101 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.525\n",
      "INFO:tensorflow:loss = 7.62549, step = 3201 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.93\n",
      "INFO:tensorflow:loss = 1.77582, step = 3301 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.881\n",
      "INFO:tensorflow:loss = 2.80163, step = 3401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.876\n",
      "INFO:tensorflow:loss = 0.46995, step = 3501 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.363\n",
      "INFO:tensorflow:loss = 0.149466, step = 3601 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.081\n",
      "INFO:tensorflow:loss = 0.55483, step = 3701 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.285\n",
      "INFO:tensorflow:loss = 5.18942, step = 3801 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.497\n",
      "INFO:tensorflow:loss = 12.5854, step = 3901 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.396\n",
      "INFO:tensorflow:loss = 4.68245, step = 4001 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.418\n",
      "INFO:tensorflow:loss = 1.35871, step = 4101 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.71\n",
      "INFO:tensorflow:loss = 0.219064, step = 4201 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.138\n",
      "INFO:tensorflow:loss = 7.79741, step = 4301 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.792\n",
      "INFO:tensorflow:loss = 3.96145, step = 4401 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.048\n",
      "INFO:tensorflow:loss = 12.7478, step = 4501 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.709\n",
      "INFO:tensorflow:loss = 1.97567, step = 4601 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.849\n",
      "INFO:tensorflow:loss = 0.0507626, step = 4701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.218\n",
      "INFO:tensorflow:loss = 13.7592, step = 4801 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.796\n",
      "INFO:tensorflow:loss = 0.431729, step = 4901 (0.180 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 22.9322.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-21-19:35:32\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-21-19:35:34\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 6.18867, rmse = 2.4877\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: abalone_output/export/Servo/1503344134/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--train-files',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-batch-size',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-batch-size',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-files',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning-rate',\n",
    "        default=0.001,\n",
    "        type=float\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-delay-secs',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min-eval-frequency',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-steps',\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-steps',\n",
    "        default=None,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    # For the purposes of running in a notebook hardcoding arguments\n",
    "    args = parser.parse_args([\n",
    "        '--train-files', 'gs://smiling-beaming-abalone/abalone_train.csv',\n",
    "        '--eval-files', 'gs://smiling-beaming-abalone/abalone_test.csv',\n",
    "        '--job-dir', 'abalone_output',\n",
    "        '--train-steps', '5000',\n",
    "        '--eval-steps', '100'\n",
    "      ])\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    learn_runner.run(\n",
    "        generate_experiment_fn(\n",
    "            min_eval_frequency=args.min_eval_frequency,\n",
    "            eval_delay_secs=args.eval_delay_secs,\n",
    "            train_steps=args.train_steps,\n",
    "            eval_steps=args.eval_steps,\n",
    "            export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "                example_serving_input_fn,\n",
    "                exports_to_keep=1\n",
    "            )]\n",
    "        ),\n",
    "        run_config=tf.contrib.learn.RunConfig(model_dir=args.job_dir),\n",
    "        hparams=hparam.HParams(**args.__dict__)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
