{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to do a little Datalab-fu to get things running on CMLE.  The essence is that once you get to the point of a working, production-grade model you'll flip from Datalab to coding in Python script files because CMLE requires this (you need to supply a python package and module to the gcloud CLI.  Personally, what I do is once I have the code in the previous notebook running in Datalab I download the script as a Python script file and switch to my editor of choice (usually vi or emacs because I don't have much left to do in essence).\n",
    "\n",
    "However, what I'll do here is create the required files via Datalab:\n",
    "\n",
    "1. Some cleanup - in case you are running this notebook multiple times - by deleting the local directories for the Python package and the model training output.\n",
    "2. Create a directory for our Python package (called trainer).\n",
    "3. Create an (empty) __init__.py file in the trainer directory (which can be empty but serves to designate the directory as a package).\n",
    "4. Take the exact same code as the last notebook (with the exception that we'll read all the arguments from the command line - in the last notebook we hardcoded some defaults) and save it in a file called task in the trainer directory.\n",
    "\n",
    "Then we can run train and evaluate the mode locally and on CMLE proper.\n",
    "\n",
    "To run locally we execute the following.\n",
    "\n",
    "```\n",
    "gcloud ml-engine local train --package-path trainer \\\n",
    "   --module-name trainer.task \\\n",
    "   -- \\\n",
    "   --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "   --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "   --job-dir abalone_output \\\n",
    "   --train-steps 5000 \\\n",
    "   --eval-steps 100\n",
    "```\n",
    "\n",
    "Which is self explanatory.  To run on CMLE we execute the following.\n",
    "\n",
    "```\n",
    "!gcloud ml-engine jobs submit training abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --stream-logs \\\n",
    "  --scale-tier STANDARD_1 \\\n",
    "  --runtime-version 1.2 \\\n",
    "  --job-dir gs://smiling-beaming-abalone/abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --module-name trainer.task \\\n",
    "  --package-path trainer \\\n",
    "  --region us-central1 \\\n",
    "  -- \\\n",
    "  --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "  --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "  --train-steps 5000 \\\n",
    "  --eval-steps 100\n",
    "```\n",
    "\n",
    "The only difference in this case is that we submit the job to the CMLE managed service and we choose a scale tier to indicate the amount of compute horsepower we want to throw at the problem.  In this case, we're using STANDARD_1 which gives us a master, three workers and three parameter servers (all CPU-based) which is teh smallest, standard footprint that gives us distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some housekeeping, we need to delete the output folder we use locally between runs (in case you run this notebook multiple times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf trainer && rm -rf abalone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!touch trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer/task.py\n",
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import (saved_model_export_utils)\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    'length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
    "    'viscera_weight', 'shell_weight', 'num_rings'\n",
    "]\n",
    "CSV_COLUMN_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "PREDICTED_COLUMN = 'num_rings'\n",
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('length'),\n",
    "    tf.feature_column.numeric_column('diameter'),\n",
    "    tf.feature_column.numeric_column('height'),\n",
    "    tf.feature_column.numeric_column('whole_weight'),\n",
    "    tf.feature_column.numeric_column('shucked_weight'),\n",
    "    tf.feature_column.numeric_column('viscera_weight'),\n",
    "    tf.feature_column.numeric_column('shell_weight'),\n",
    "]\n",
    "\n",
    "UNUSED_COLUMNS = set(CSV_COLUMNS) - {col.name for col in INPUT_COLUMNS} - {PREDICTED_COLUMN}\n",
    "\n",
    "def parse_csv(rows_string_tensor):\n",
    "    columns = tf.decode_csv(rows_string_tensor, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "\n",
    "    for col in UNUSED_COLUMNS:\n",
    "        features.pop(col)\n",
    "\n",
    "    for key, value in six.iteritems(features):\n",
    "        features[key] = tf.expand_dims(features[key], -1)\n",
    "    return features\n",
    "\n",
    "def generate_input_fn(filenames,\n",
    "                      num_epochs=None,\n",
    "                      shuffle=True,\n",
    "                      skip_header_lines=0,\n",
    "                      batch_size=64):\n",
    "  \n",
    "    def _input_fn():\n",
    "  \n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=shuffle)\n",
    "        reader = tf.TextLineReader(skip_header_lines=skip_header_lines)\n",
    "\n",
    "        _, rows = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "        features = parse_csv(rows)\n",
    "\n",
    "        if shuffle:\n",
    "            features = tf.train.shuffle_batch(\n",
    "                features,\n",
    "                batch_size,\n",
    "                min_after_dequeue=2 * batch_size + 1,\n",
    "                capacity=batch_size * 10,\n",
    "                num_threads=multiprocessing.cpu_count(),\n",
    "                enqueue_many=True,\n",
    "                allow_smaller_final_batch=True\n",
    "            )\n",
    "        else:\n",
    "            features = tf.train.batch(\n",
    "                features,\n",
    "                batch_size,\n",
    "                capacity=batch_size * 10,\n",
    "                num_threads=multiprocessing.cpu_count(),\n",
    "                enqueue_many=True,\n",
    "                allow_smaller_final_batch=True\n",
    "            )\n",
    "\n",
    "        return features, features.pop(PREDICTED_COLUMN)\n",
    "  \n",
    "    return _input_fn\n",
    "\n",
    "def generate_model_fn(learning_rate):\n",
    "    \n",
    "    def _model_fn(mode, features, labels):\n",
    "\n",
    "        (length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight) = INPUT_COLUMNS\n",
    "\n",
    "        transformed_columns = [\n",
    "            length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight\n",
    "        ]\n",
    "\n",
    "        inputs = tf.feature_column.input_layer(features, transformed_columns)\n",
    "\n",
    "        first_hidden_layer = Dense(10, activation='relu')(inputs)\n",
    "        second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "        output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "        if mode in (Modes.PREDICT, Modes.EVAL):\n",
    "            predictions = tf.reshape(output_layer, [-1])\n",
    "            predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "        if mode in (Modes.TRAIN, Modes.EVAL):\n",
    "            loss = tf.losses.mean_squared_error(labels, output_layer)\n",
    "\n",
    "        if mode == Modes.TRAIN:\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                global_step=tf.contrib.framework.get_global_step(),\n",
    "                learning_rate=learning_rate,\n",
    "                optimizer=\"SGD\")\n",
    "        \n",
    "        if mode == Modes.TRAIN:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        if mode == Modes.EVAL:\n",
    "            eval_metric_ops = {\n",
    "                \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "                    tf.cast(labels, tf.float32), predictions)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "        if mode == Modes.PREDICT:\n",
    "            export_outputs = {\n",
    "                'prediction': tf.estimator.export.RegressionOutput(predictions)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, predictions=predictions_dict, export_outputs=export_outputs)\n",
    "    \n",
    "    return _model_fn\n",
    "\n",
    "def generate_experiment_fn(**experiment_args):  \n",
    "  \n",
    "    def _experiment_fn(run_config, hparams):\n",
    "\n",
    "        train_input = generate_input_fn(\n",
    "            hparams.train_files,\n",
    "            num_epochs=hparams.num_epochs,\n",
    "            batch_size=hparams.train_batch_size,\n",
    "        )\n",
    "\n",
    "        test_input = generate_input_fn(\n",
    "            hparams.eval_files,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        return tf.contrib.learn.Experiment(\n",
    "            tf.estimator.Estimator(\n",
    "                generate_model_fn(learning_rate=hparams.learning_rate),\n",
    "                config=run_config\n",
    "            ),\n",
    "            train_input_fn=train_input,\n",
    "            eval_input_fn=test_input,\n",
    "            **experiment_args\n",
    "        )\n",
    "\n",
    "    return _experiment_fn\n",
    "\n",
    "def example_serving_input_fn():\n",
    "    example_bytestring = tf.placeholder(\n",
    "        shape=[None],\n",
    "        dtype=tf.string,\n",
    "    )\n",
    "    features = tf.parse_example(\n",
    "        example_bytestring,\n",
    "        tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "    )\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features, {'example_proto': example_bytestring})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--train-files',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-batch-size',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-batch-size',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-files',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning-rate',\n",
    "        default=0.001,\n",
    "        type=float\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-delay-secs',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min-eval-frequency',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-steps',\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-steps',\n",
    "        default=None,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    # For the purposes of running in a notebook hardcoding arguments\n",
    "    '''args = parser.parse_args([\n",
    "        '--train-files', 'gs://smiling-beaming-abalone/abalone_train.csv',\n",
    "        '--eval-files', 'gs://smiling-beaming-abalone/abalone_test.csv',\n",
    "        '--job-dir', 'abalone_output',\n",
    "        '--train-steps', '5000',\n",
    "        '--eval-steps', '100'\n",
    "      ])'''\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    learn_runner.run(\n",
    "        generate_experiment_fn(\n",
    "            min_eval_frequency=args.min_eval_frequency,\n",
    "            eval_delay_secs=args.eval_delay_secs,\n",
    "            train_steps=args.train_steps,\n",
    "            eval_steps=args.eval_steps,\n",
    "            export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "                example_serving_input_fn,\n",
    "                exports_to_keep=1\n",
    "            )]\n",
    "        ),\n",
    "        run_config=tf.contrib.learn.RunConfig(model_dir=args.job_dir),\n",
    "        hparams=hparam.HParams(**args.__dict__)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the code locally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'abalone_output', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': u'cloud', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4587df95d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-08-21 19:35:55.154728: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-21 19:35:55.154834: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-21 19:35:55.154845: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-21 19:35:55.154853: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-21 19:35:55.154860: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-21-19:35:55\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-21-19:35:58\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 114.772, rmse = 10.7132\n",
      "INFO:tensorflow:Validation (step 1): loss = 114.772, global_step = 1, rmse = 10.7132\n",
      "INFO:tensorflow:loss = 103.758, step = 1\n",
      "INFO:tensorflow:global_step/sec: 34.7459\n",
      "INFO:tensorflow:loss = 4.09442, step = 101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.337\n",
      "INFO:tensorflow:loss = 2.26993, step = 201 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.851\n",
      "INFO:tensorflow:loss = 6.56661, step = 301 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.389\n",
      "INFO:tensorflow:loss = 2.35126, step = 401 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.974\n",
      "INFO:tensorflow:loss = 10.3992, step = 501 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.93\n",
      "INFO:tensorflow:loss = 4.77574, step = 601 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.412\n",
      "INFO:tensorflow:loss = 13.4071, step = 701 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.6\n",
      "INFO:tensorflow:loss = 0.10146, step = 801 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.964\n",
      "INFO:tensorflow:loss = 5.41859, step = 901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.348\n",
      "INFO:tensorflow:loss = 0.0584074, step = 1001 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.697\n",
      "INFO:tensorflow:loss = 4.86845, step = 1101 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.514\n",
      "INFO:tensorflow:loss = 0.140354, step = 1201 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.355\n",
      "INFO:tensorflow:loss = 5.14719, step = 1301 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.694\n",
      "INFO:tensorflow:loss = 2.85518, step = 1401 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.373\n",
      "INFO:tensorflow:loss = 1.03188, step = 1501 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.927\n",
      "INFO:tensorflow:loss = 0.192471, step = 1601 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.58\n",
      "INFO:tensorflow:loss = 2.79226, step = 1701 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.187\n",
      "INFO:tensorflow:loss = 8.26199, step = 1801 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.094\n",
      "INFO:tensorflow:loss = 0.142851, step = 1901 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.394\n",
      "INFO:tensorflow:loss = 8.21153, step = 2001 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.276\n",
      "INFO:tensorflow:loss = 0.447979, step = 2101 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.527\n",
      "INFO:tensorflow:loss = 1.00975, step = 2201 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.157\n",
      "INFO:tensorflow:loss = 2.92555, step = 2301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.173\n",
      "INFO:tensorflow:loss = 1.61965, step = 2401 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.613\n",
      "INFO:tensorflow:loss = 4.24673, step = 2501 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.232\n",
      "INFO:tensorflow:loss = 4.46624, step = 2601 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.107\n",
      "INFO:tensorflow:loss = 0.170108, step = 2701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.339\n",
      "INFO:tensorflow:loss = 0.929415, step = 2801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.452\n",
      "INFO:tensorflow:loss = 0.0935752, step = 2901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.304\n",
      "INFO:tensorflow:loss = 3.21067, step = 3001 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.855\n",
      "INFO:tensorflow:loss = 1.43165, step = 3101 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.421\n",
      "INFO:tensorflow:loss = 1.57271, step = 3201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.03\n",
      "INFO:tensorflow:loss = 0.0997192, step = 3301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.564\n",
      "INFO:tensorflow:loss = 1.65536, step = 3401 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.555\n",
      "INFO:tensorflow:loss = 0.339727, step = 3501 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.632\n",
      "INFO:tensorflow:loss = 1.25619, step = 3601 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.989\n",
      "INFO:tensorflow:loss = 0.0847681, step = 3701 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 560.438\n",
      "INFO:tensorflow:loss = 4.01495, step = 3801 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.541\n",
      "INFO:tensorflow:loss = 7.22632, step = 3901 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.26\n",
      "INFO:tensorflow:loss = 1.24833, step = 4001 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.119\n",
      "INFO:tensorflow:loss = 0.828773, step = 4101 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.782\n",
      "INFO:tensorflow:loss = 3.33839, step = 4201 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.693\n",
      "INFO:tensorflow:loss = 0.52752, step = 4301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.182\n",
      "INFO:tensorflow:loss = 1.47396, step = 4401 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.953\n",
      "INFO:tensorflow:loss = 2.35942, step = 4501 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.413\n",
      "INFO:tensorflow:loss = 28.5355, step = 4601 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.167\n",
      "INFO:tensorflow:loss = 0.368903, step = 4701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.29\n",
      "INFO:tensorflow:loss = 0.804254, step = 4801 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.097\n",
      "INFO:tensorflow:loss = 60.4904, step = 4901 (0.188 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 50.582.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-21-19:36:08\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-21-19:36:10\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 6.00282, rmse = 2.45006\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: abalone_output/export/Servo/1503344170/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine local train --package-path trainer \\\n",
    "   --module-name trainer.task \\\n",
    "   -- \\\n",
    "   --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "   --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "   --job-dir abalone_output \\\n",
    "   --train-steps 5000 \\\n",
    "   --eval-steps 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code on CMLE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [abalone_170821_193611] submitted successfully.\n",
      "INFO\t2017-08-21 19:36:13 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2017-08-21 19:36:14 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2017-08-21 19:36:14 +0000\tservice\t\tJob abalone_170821_193611 is queued.\n",
      "INFO\t2017-08-21 19:36:14 +0000\tservice\t\tWaiting for job to be provisioned.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs submit training abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --stream-logs \\\n",
    "  --scale-tier STANDARD_1 \\\n",
    "  --runtime-version 1.2 \\\n",
    "  --job-dir gs://smiling-beaming-abalone/abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --module-name trainer.task \\\n",
    "  --package-path trainer \\\n",
    "  --region us-central1 \\\n",
    "  -- \\\n",
    "  --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "  --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "  --train-steps 5000 \\\n",
    "  --eval-steps 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
