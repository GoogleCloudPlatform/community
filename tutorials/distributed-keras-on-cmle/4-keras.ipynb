{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll change our model.  Originally it was defined using tf.contrib.layers, we'll change that to Keras.  Keras is being integrated as a first class citizen in TensorFlow and we'll use the version of Keras in tf.contrib.keras.  Originally the code looked like the following.\n",
    "\n",
    "```\n",
    "first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "```\n",
    "\n",
    "The Keras version of the model looks like the following.\n",
    "\n",
    "```\n",
    "first_hidden_layer = Dense(10, activation='relu')(features)\n",
    "second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "```\n",
    "\n",
    "Both of these models are similarly concise because the aim of both is to provide an abstraction from raw TensorFlow.  The point of this solution is not to propose Keras as either superior or inferior to tf.contrib.learn or tf.contrib.layers.  The point is that it is enormously powerful and benefical to (a) be able to access Keras from the TensorFlow distribution and (b) to be able to mix and match tf.contrib.learn, tf.contrib.layers and Keras in the same model.\n",
    "\n",
    "You should familiarize yourself with the changes made, run this notebook in its entirety, then proceed to the [next notebook](5-keras-full.ipynb).\n",
    "\n",
    "The output from training and evaluation will be the same as before (N.B. because of the nature of neural net training the actual numbers will be similar but not exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FILENAME = 'abalone_train.csv'\n",
    "TEST_FILENAME = 'abalone_test.csv'\n",
    "  \n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=TRAINING_FILENAME, target_dtype=np.int, features_dtype=np.float32)\n",
    "test_dataset = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=TEST_FILENAME, target_dtype=np.int, features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras.losses import mean_squared_error\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \n",
    "    first_hidden_layer = Dense(10, activation='relu')(features)\n",
    "    second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "    output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "    predictions = tf.reshape(output_layer, [-1])\n",
    "    predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "    loss = mean_squared_error(tf.cast(targets, tf.float32), predictions)\n",
    "\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(tf.cast(targets, tf.float32), predictions)\n",
    "    }\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"SGD\")\n",
    "\n",
    "    return model_fn_lib.ModelFnOps(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpuDNVz9\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8ce754ad50>, '_model_dir': '/tmp/tmpuDNVz9', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpuDNVz9/model.ckpt.\n",
      "INFO:tensorflow:loss = 106.605, step = 1\n",
      "INFO:tensorflow:global_step/sec: 543.771\n",
      "INFO:tensorflow:loss = 7.6023, step = 101 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.988\n",
      "INFO:tensorflow:loss = 7.22128, step = 201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.037\n",
      "INFO:tensorflow:loss = 7.04075, step = 301 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.382\n",
      "INFO:tensorflow:loss = 6.9378, step = 401 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.399\n",
      "INFO:tensorflow:loss = 6.86537, step = 501 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.728\n",
      "INFO:tensorflow:loss = 6.80615, step = 601 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.664\n",
      "INFO:tensorflow:loss = 6.75228, step = 701 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.108\n",
      "INFO:tensorflow:loss = 6.70044, step = 801 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.855\n",
      "INFO:tensorflow:loss = 6.64897, step = 901 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.377\n",
      "INFO:tensorflow:loss = 6.59705, step = 1001 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.542\n",
      "INFO:tensorflow:loss = 6.54425, step = 1101 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.959\n",
      "INFO:tensorflow:loss = 6.49035, step = 1201 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 596.787\n",
      "INFO:tensorflow:loss = 6.43518, step = 1301 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.845\n",
      "INFO:tensorflow:loss = 6.37865, step = 1401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.919\n",
      "INFO:tensorflow:loss = 6.3207, step = 1501 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.355\n",
      "INFO:tensorflow:loss = 6.26132, step = 1601 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.735\n",
      "INFO:tensorflow:loss = 6.2005, step = 1701 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.413\n",
      "INFO:tensorflow:loss = 6.13826, step = 1801 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.42\n",
      "INFO:tensorflow:loss = 6.07463, step = 1901 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.084\n",
      "INFO:tensorflow:loss = 6.00978, step = 2001 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.729\n",
      "INFO:tensorflow:loss = 5.94385, step = 2101 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.249\n",
      "INFO:tensorflow:loss = 5.87704, step = 2201 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.84\n",
      "INFO:tensorflow:loss = 5.80971, step = 2301 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.687\n",
      "INFO:tensorflow:loss = 5.74209, step = 2401 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.104\n",
      "INFO:tensorflow:loss = 5.6747, step = 2501 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.091\n",
      "INFO:tensorflow:loss = 5.60801, step = 2601 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.377\n",
      "INFO:tensorflow:loss = 5.54236, step = 2701 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.849\n",
      "INFO:tensorflow:loss = 5.47835, step = 2801 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.25\n",
      "INFO:tensorflow:loss = 5.41645, step = 2901 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.529\n",
      "INFO:tensorflow:loss = 5.35693, step = 3001 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.251\n",
      "INFO:tensorflow:loss = 5.30043, step = 3101 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.235\n",
      "INFO:tensorflow:loss = 5.24704, step = 3201 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.983\n",
      "INFO:tensorflow:loss = 5.19662, step = 3301 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.805\n",
      "INFO:tensorflow:loss = 5.15016, step = 3401 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.987\n",
      "INFO:tensorflow:loss = 5.10812, step = 3501 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.844\n",
      "INFO:tensorflow:loss = 5.07023, step = 3601 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.013\n",
      "INFO:tensorflow:loss = 5.03622, step = 3701 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.665\n",
      "INFO:tensorflow:loss = 5.00578, step = 3801 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.998\n",
      "INFO:tensorflow:loss = 4.97883, step = 3901 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.955\n",
      "INFO:tensorflow:loss = 4.95508, step = 4001 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.311\n",
      "INFO:tensorflow:loss = 4.93426, step = 4101 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.822\n",
      "INFO:tensorflow:loss = 4.9158, step = 4201 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.842\n",
      "INFO:tensorflow:loss = 4.89946, step = 4301 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.217\n",
      "INFO:tensorflow:loss = 4.88555, step = 4401 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.409\n",
      "INFO:tensorflow:loss = 4.87344, step = 4501 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.076\n",
      "INFO:tensorflow:loss = 4.86284, step = 4601 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.731\n",
      "INFO:tensorflow:loss = 4.85325, step = 4701 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.735\n",
      "INFO:tensorflow:loss = 4.84466, step = 4801 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.931\n",
      "INFO:tensorflow:loss = 4.83702, step = 4901 (0.160 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpuDNVz9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.83027.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-21-19:34:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpuDNVz9/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-21-19:34:57\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.55508, rmse = 2.35692\n",
      "Loss: 5.55508\n",
      "Root Mean Squared Error: 2.35692\n"
     ]
    }
   ],
   "source": [
    "model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "def get_train_inputs():\n",
    "    x = tf.constant(training_dataset.data)\n",
    "    y = tf.constant(training_dataset.target)\n",
    "    return x, y\n",
    "\n",
    "nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(test_dataset.data)\n",
    "    y = tf.constant(test_dataset.target)\n",
    "    return x, y\n",
    "\n",
    "ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "print(\"Loss: %s\" % ev[\"loss\"])\n",
    "print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
